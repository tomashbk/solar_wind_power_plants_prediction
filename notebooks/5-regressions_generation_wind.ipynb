{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyhere\n",
    "import sys\n",
    "sys.path.insert(0, str(pyhere.here().resolve().joinpath(\"src\")))\n",
    "import utils\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, QuantileRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV, StratifiedKFold, cross_validate, validation_curve, learning_curve, cross_val_predict, KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, get_scorer_names, mean_pinball_loss, make_scorer\n",
    "from sklearn.ensemble import RandomForestRegressor, IsolationForest, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler, PowerTransformer, StandardScaler, PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from statsmodels import api as sm\n",
    "import joblib\n",
    "from mapie.regression import MapieRegressor\n",
    "from mapie.metrics import regression_coverage_score\n",
    "from mapie.quantile_regression import MapieQuantileRegressor\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def capacity_factor_formula:\n",
    "#     hours_year = 8760\n",
    "#     capacity_factor = generation / (capacity * hours_year)\n",
    "\n",
    "def validation_curve_plot(plot_title, model, X, y, param_name, param_range):\n",
    "    train_scores, test_scores = validation_curve(\n",
    "            model,\n",
    "            X,\n",
    "            y,\n",
    "            param_name = param_name,\n",
    "            param_range = param_range,\n",
    "            cv = 5\n",
    "        )\n",
    "        \n",
    "    np.mean(train_scores, axis=1)\n",
    "    \n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(np.mean(train_scores, axis=1),\n",
    "        label = \"Training Score\", color = 'b')\n",
    "    plt.plot(np.mean(test_scores, axis=1),\n",
    "    label = \"Cross Validation Score\", color = 'g')\n",
    "    plt.xticks(np.arange(param_range.shape[0]), param_range)\n",
    "    plt.title(plot_title)\n",
    "    plt.legend()\n",
    "\n",
    "def learning_curve_plot(plot_title, model_with_hp, X, y):\n",
    "    lc = learning_curve(model_with_hp, X, y, cv=5)\n",
    "    samples, train, test = lc[0], lc[1], lc[2]\n",
    "    \n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(samples, np.mean(train, axis=1),\n",
    "        label = \"Training Score\", color = 'b')\n",
    "    plt.plot(samples, np.mean(test, axis=1),\n",
    "    label = \"Cross Validation Score\", color = 'g')\n",
    "    plt.title(plot_title)\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "# def performance_metrics(y_true, y_pred, dataset_type):\n",
    "def performance_metrics_cross_val(X, y, model_with_hp, dataset_type):\n",
    "    results = cross_validate(\n",
    "        model_with_hp,\n",
    "        X, \n",
    "        y, \n",
    "        cv=5, \n",
    "        scoring=(\n",
    "            'r2', \n",
    "            'neg_mean_squared_error', \n",
    "            'neg_mean_absolute_error',\n",
    "            'neg_root_mean_squared_error')\n",
    "    )\n",
    "\n",
    "    dict_results = {}\n",
    "    for i, val in results.items():\n",
    "        if 'test' in i:\n",
    "            if 'neg' in i:\n",
    "                dict_results[i.replace(\"neg_\", \"\")] = -np.mean(val)\n",
    "\n",
    "                # if 'mean_squared_error' in i:\n",
    "                #     dict_results['test_root_mean_squared_error'] = np.sqrt(-np.mean(val))\n",
    "            else:\n",
    "                dict_results[i] = np.mean(val)\n",
    "    return dict_results\n",
    "    # cross_val_score(lasso, X, y, cv=5)\n",
    "    # cross_val_score(nb_model_1, X, y, cv=StratifiedKFold(shuffle = True))\n",
    "    # r2 = r2_score(y_true, y_pred)\n",
    "    # mse = mean_squared_error(y_true, y_pred)\n",
    "    # rmse = np.sqrt(mse) \n",
    "    # mae = mean_absolute_error(y_true, y_pred)\n",
    "    # return pd.DataFrame({'metrica': ['R2', 'MSE', 'RMSE', 'MAE'],\n",
    "    #                      'valor':[r2, mse, rmse, mae],\n",
    "    #                      'dataset_type':dataset_type})\n",
    "                         \n",
    "    \n",
    "def coef_summary(results):\n",
    "    '''\n",
    "    Toma los resultado del modelo de OLS \n",
    "    \n",
    "    Elimina el intercepto.\n",
    "    '''\n",
    "    # Creo un dataframe de los resultados del summary \n",
    "    coef_df = pd.DataFrame(results.summary().tables[1].data)\n",
    "    \n",
    "    # Agrego el nombre de las columnas\n",
    "    coef_df.columns = coef_df.iloc[0]\n",
    "\n",
    "    # Elimino la fila extra del intercepto\n",
    "    coef_df=coef_df.drop(0)\n",
    "\n",
    "    # Seteo el nombre de las variables como index\n",
    "    coef_df = coef_df.set_index(coef_df.columns[0])\n",
    "\n",
    "    # Convertimos a float los object \n",
    "    coef_df = coef_df.astype(float)\n",
    "\n",
    "    # Obtenemos el error; (coef - limite inferior del IC)\n",
    "    errors = coef_df['coef'] - coef_df['[0.025']\n",
    "    \n",
    "    # Agregamos los errores al dataframe\n",
    "    coef_df['errors'] = errors\n",
    "\n",
    "    # Eliminamos la variable const\n",
    "    coef_df = coef_df.drop(['const'])\n",
    "\n",
    "    # Ordenamos los coeficientes \n",
    "    coef_df = coef_df.sort_values(by=['coef'])\n",
    "\n",
    "    ### Graficamos ###\n",
    "\n",
    "    # x-labels\n",
    "    variables = list(coef_df.index.values)\n",
    "    \n",
    "    # Agregamos la columna con el nombre de las variables\n",
    "    coef_df['variables'] = variables\n",
    "   \n",
    "    return  coef_df\n",
    "\n",
    "    \n",
    "def adjusted_r2(X, y_true, y_pred):   \n",
    "    print((1-(1-r2_score(y_true, y_pred))*((len(X)-1))/(len(X)-len(X.columns)-1)))\n",
    "\n",
    "def generate_results_dataset(preds, ci):\n",
    "    df = pd.DataFrame()\n",
    "    df['prediction'] = preds\n",
    "    if ci >= 0:\n",
    "        df['upper'] = preds + ci\n",
    "        df['lower'] = preds - ci\n",
    "    else:\n",
    "        df['upper'] = preds - ci\n",
    "        df['lower'] = preds + ci\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATAFRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_power_plants = pd.read_csv(utils.DIR_DATA_INTERIM/\"power_plants_with_generation_transformed.csv\", index_col=[0])\n",
    "# df_transformed = pd.read_csv(utils.DIR_DATA_EXTERNAL/\"v2_transformed_data_combined_with_nasa.csv\", index_col=['index'])\n",
    "df_transformed = pd.read_csv(utils.DIR_DATA_EXTERNAL/\"v5_transformed_data_combined_with_nasa.csv\", index_col=['index'])\n",
    "# csv_power_plants.loc[0:34935, ['capacity_mw', 'primary_fuel_transformed']].index.name = \"index\"\n",
    "csv_power_plants.index.rename('index', inplace=True)\n",
    "df_power_plants_raw = pd.read_csv(utils.DIR_DATA_RAW/\"global_power_plant_database.csv\", usecols=['name','primary_fuel', 'estimated_generation_gwh_2013'], engine='python')\n",
    "csv_power_plants = csv_power_plants.join(df_power_plants_raw)\n",
    "\n",
    "# index_set_to_delete = csv_power_plants[csv_power_plants['other_fuel1'].isin(['Solar', 'Wind'])].index.tolist()\n",
    "# index_set_to_delete += (csv_power_plants[csv_power_plants['other_fuel2'].isin(['Solar', 'Wind'])].index.tolist())\n",
    "# index_set_to_delete += (csv_power_plants[csv_power_plants['other_fuel3'].isin(['Solar', 'Wind'])].index.tolist())\n",
    "\n",
    "# csv_power_plants.drop(index_set_to_delete, inplace = True)\n",
    "columns_to_combine = [\n",
    "                        'name',\n",
    "                        'capacity_mw',\n",
    "                        'primary_fuel_transformed',\n",
    "                        # 'other_fuel1',\n",
    "                        # 'other_fuel2',\n",
    "                        # 'other_fuel3',\n",
    "                        'generation_gwh_2013',\n",
    "                        'generation_gwh_2014',\n",
    "                        'generation_gwh_2015',\n",
    "                        'generation_gwh_2016',\n",
    "                        'generation_gwh_2017',\n",
    "                        'generation_gwh_2018',\n",
    "                        # 'estimated_generation_gwh_2013',\n",
    "                        # 'generation_gwh_2019'\n",
    "                    ]\n",
    "# df_transformed_combined = df_transformed.merge(csv_power_plants.loc[0:24360, ['capacity_mw', 'primary_fuel_transformed']],left_on=\"index\", right_on=\"index\")\n",
    "df_transformed_combined = df_transformed.merge(csv_power_plants[columns_to_combine],left_on=\"index\", right_on=\"index\")\n",
    "print(df_transformed_combined[['primary_fuel_transformed']].value_counts())\n",
    "df_transformed_combined[['primary_fuel_transformed']].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wind = df_transformed_combined[df_transformed_combined['primary_fuel_transformed']== \"Wind\"]\n",
    "# df_wind = df_wind[~df_wind['name'].str.contains('CSP')]\n",
    "df_wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_wind_attempt = df_wind[df_wind['generation_gwh_2013'].isna() & df_wind['estimated_generation_gwh_2013'].notna()]\n",
    "# # df_wind_attempt.loc[:,['generation_gwh_2013']] = 23.23\n",
    "# # df_wind_attempt.loc[:,['generation_gwh_2013']] = df_wind_attempt.loc[:,['estimated_generation_gwh_2013']].copy()\n",
    "# df_wind.loc[df_wind_attempt.index, ['generation_gwh_2013']] = df_wind_attempt.loc[:,['estimated_generation_gwh_2013']]\n",
    "\n",
    "# df_wind['generation_gwh_2013'].fillna(df_wind['estimated_generation_gwh_2013'], inplace=True)\n",
    "\n",
    "# # df_wind[df_wind['generation_gwh_2013'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_wind_alt = df_wind[df_wind['generation_gwh_2013'].notna()]\n",
    "# df_wind_alt['generation_gwh_2013'].value_counts().hist(bins=10)\n",
    "# print(df_wind_alt[df_wind_alt['generation_gwh_2013'] < 20]['generation_gwh_2013'].count())\n",
    "# print(df_wind_alt.loc[(df_wind_alt['generation_gwh_2013'] >= 20) & (df_wind_alt['generation_gwh_2013'] < 100)]['generation_gwh_2013'].count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_wind_alt.loc[df_wind_alt['capacity_mw'] == (df_wind_alt['capacity_mw'].value_counts()>20)]\n",
    "# indexes = df_wind_alt['capacity_mw'].isin(df_wind_alt['capacity_mw'].value_counts()>20).index\n",
    "# df_wind_alt['capacity_mw'].value_counts().values>20\n",
    "# df_wind_alt.loc[indexes]['capacity_mw']\n",
    "# df_wind_alt[df_wind_alt['capacity_mw'] == 145]\n",
    "# df_wind_alt[df_wind_alt['capacity_mw'].isin(df_wind_alt['capacity_mw'].value_counts()[df_wind_alt['capacity_mw'].value_counts()>20].index)].capacity_mw\n",
    "# df_wind_alt_more_than_20 = df_wind_alt[df_wind_alt['capacity_mw'].isin(df_wind_alt['capacity_mw'].value_counts()[df_wind_alt['capacity_mw'].value_counts()>20].index)]\n",
    "# df_wind_alt_more_than_20['capacity_mw'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.calculate_feature_mean_std(df_wind_alt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wind_2013 = df_wind[df_wind['generation_gwh_2013'].notna()]\n",
    "df_wind_2014 = df_wind[df_wind['generation_gwh_2014'].notna()]\n",
    "df_wind_2015 = df_wind[df_wind['generation_gwh_2015'].notna()]\n",
    "df_wind_2016 = df_wind[df_wind['generation_gwh_2016'].notna()]\n",
    "df_wind_2017 = df_wind[df_wind['generation_gwh_2017'].notna()]\n",
    "df_wind_2018 = df_wind[df_wind['generation_gwh_2018'].notna()]\n",
    "# columns_delete = df_wind.columns.str.contains('WS') | df_wind.columns.str.contains('primary_fuel_transformed') | df_wind.columns.str.contains('latitude') | df_wind.columns.str.contains('longitude') | df_wind.columns.str.contains('2019') | df_wind.columns.str.contains('2012') | df_wind.columns.str.contains('2013') | df_wind.columns.str.contains('2014') | df_wind.columns.str.contains('2015') | df_wind.columns.str.contains('2016') | df_wind.columns.str.contains('2017') | df_wind.columns.str.contains('2018') |  df_wind.columns.str.contains('ANN') |  df_wind.columns.str.contains('LW') |  df_wind.columns.str.contains('WS10') | df_wind.columns.str.contains('MAX')\n",
    "# columns_delete = df_wind_alt.columns.str.contains('primary_fuel_transformed') | df_wind.columns.str.contains('latitude') | df_wind.columns.str.contains('longitude') | df_wind.columns.str.contains('2019') | df_wind.columns.str.contains('2012') | df_wind.columns.str.contains('2013') | df_wind.columns.str.contains('2014') | df_wind.columns.str.contains('2015') | df_wind.columns.str.contains('2016') | df_wind.columns.str.contains('2017') | df_wind.columns.str.contains('2018') \n",
    "# columns_delete = df_wind_alt.columns.str.contains('2013') | df_wind_alt.columns.str.contains('generation_gwh_2013') | df_wind_alt.columns.str.contains('estimated_generation_gwh_2013') | df_wind_alt.columns.str.contains('WS') | df_wind_alt.columns.str.contains('name') | df_wind_alt.columns.str.contains('primary_fuel_transformed') | df_wind_alt.columns.str.contains('latitude') | df_wind_alt.columns.str.contains('longitude') | df_wind_alt.columns.str.contains('2019') | df_wind_alt.columns.str.contains('2012') | df_wind_alt.columns.str.contains('2014') | df_wind_alt.columns.str.contains('2015') | df_wind_alt.columns.str.contains('2016') | df_wind_alt.columns.str.contains('2017') | df_wind_alt.columns.str.contains('2018') \n",
    "columns_keep_2013 = df_wind_2013.columns.str.contains('2013') | df_wind_2013.columns.str.contains('capacity_mw')\n",
    "columns_keep_2014 = df_wind_2014.columns.str.contains('2014') | df_wind_2014.columns.str.contains('capacity_mw')\n",
    "columns_keep_2015 = df_wind_2015.columns.str.contains('2015') | df_wind_2015.columns.str.contains('capacity_mw')\n",
    "columns_keep_2016 = df_wind_2016.columns.str.contains('2016') | df_wind_2016.columns.str.contains('capacity_mw')\n",
    "columns_keep_2017 = df_wind_2017.columns.str.contains('2017') | df_wind_2017.columns.str.contains('capacity_mw')\n",
    "columns_keep_2018 = df_wind_2018.columns.str.contains('2018') | df_wind_2018.columns.str.contains('capacity_mw')\n",
    "# df_wind_2 = df_wind_alt_more_than_20.loc[:,~columns_delete]\n",
    "# df_wind_2013 = df_wind_alt.loc[:,~columns_delete]\n",
    "df_wind_2013 = df_wind_2013.loc[:,columns_keep_2013]\n",
    "df_wind_2014 = df_wind_2014.loc[:,columns_keep_2014]\n",
    "df_wind_2015 = df_wind_2015.loc[:,columns_keep_2015]\n",
    "df_wind_2016 = df_wind_2016.loc[:,columns_keep_2016]\n",
    "df_wind_2017 = df_wind_2017.loc[:,columns_keep_2017]\n",
    "df_wind_2018 = df_wind_2018.loc[:,columns_keep_2018]\n",
    "# columns_delete_2013 = df_wind_2013.columns.str.contains('WS')\n",
    "df_wind_2013 = df_wind_2013.loc[:,~df_wind_2013.columns.str.contains('SKY')]\n",
    "df_wind_2014 = df_wind_2014.loc[:,~df_wind_2014.columns.str.contains('SKY')]\n",
    "df_wind_2015 = df_wind_2015.loc[:,~df_wind_2015.columns.str.contains('SKY')]\n",
    "df_wind_2016 = df_wind_2016.loc[:,~df_wind_2016.columns.str.contains('SKY')]\n",
    "df_wind_2017 = df_wind_2017.loc[:,~df_wind_2017.columns.str.contains('SKY')]\n",
    "df_wind_2018 = df_wind_2018.loc[:,~df_wind_2018.columns.str.contains('SKY')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_columns_2013 = {a:a.replace('_2013', '') for a in df_wind_2013.columns}\n",
    "dict_columns_2014 = {a:a.replace('_2014', '') for a in df_wind_2014.columns}\n",
    "dict_columns_2015 = {a:a.replace('_2015', '') for a in df_wind_2015.columns}\n",
    "dict_columns_2016 = {a:a.replace('_2016', '') for a in df_wind_2016.columns}\n",
    "dict_columns_2017 = {a:a.replace('_2017', '') for a in df_wind_2017.columns}\n",
    "dict_columns_2018 = {a:a.replace('_2018', '') for a in df_wind_2018.columns}\n",
    "df_wind_2013.rename(columns=dict_columns_2013, inplace=True)\n",
    "df_wind_2014.rename(columns=dict_columns_2014, inplace=True)\n",
    "df_wind_2015.rename(columns=dict_columns_2015, inplace=True)\n",
    "df_wind_2016.rename(columns=dict_columns_2016, inplace=True)\n",
    "df_wind_2017.rename(columns=dict_columns_2017, inplace=True)\n",
    "df_wind_2018.rename(columns=dict_columns_2018, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wind_2018.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_concat = pd.concat([df_wind_2013,df_wind_2014,df_wind_2015,df_wind_2016,df_wind_2017,df_wind_2018])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_concat.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_concat['generation_gwh'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_concat = df_all_concat[df_all_concat['generation_gwh'] <=30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_concat['capacity_factor'] = df_all_concat['generation_gwh'] / ((df_all_concat['capacity_mw'] / 1000) * 8760)\n",
    "df_all_concat = df_all_concat[(df_all_concat['capacity_factor'] > 0.1) & (df_all_concat['capacity_factor'] < 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_concat[(df_all_concat['capacity_factor'] <=0.1)]['capacity_factor'].count()\n",
    "\n",
    "# df_all_concat[(df_all_concat['capacity_factor'] >=0.01) & (df_all_concat['capacity_factor'] < 1.00)]['capacity_factor'].count()\n",
    "# df_all_concat[(df_all_concat['capacity_factor'] >=.9)]['capacity_factor'].count()\n",
    "# df_all_concat[df_all_concat['capacity_factor'] <=0]\n",
    "# df_all_concat[(df_all_concat['capacity_factor'] >=0.01) & (df_all_concat['capacity_factor'] < 1.00)]['capacity_factor'].count()\n",
    "# df_all_concat = df_all_concat[(df_all_concat['capacity_factor'] > 0) & (df_all_concat['capacity_factor'] < 1)]\n",
    "df_all_concat['capacity_factor'].describe()\n",
    "# type(df_all_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REMOVING OUTLIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_concat.drop(df_all_concat[df_all_concat['generation_gwh'] <= 0].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# columns_not_consider_outliers = [\n",
    "#                                     'capacity_mw',\n",
    "#                                     'latitude',\n",
    "#                                     'longitude',\n",
    "#                                     'primary_fuel_transformed',\n",
    "#                                     'code_prim_fuel_transf',\n",
    "#                                     'generation_gwh_2013',\n",
    "#                                     'generation_gwh_2014',\n",
    "#                                     'generation_gwh_2015',\n",
    "#                                     'generation_gwh_2016',\n",
    "#                                     'generation_gwh_2017',\n",
    "#                                     'generation_gwh_2018',\n",
    "#                                     'generation_gwh_2019'\n",
    "#                                 ]\n",
    "# X = X.loc[:,~columns_delete]                        \n",
    "df_all_concat_remove_outliers = df_all_concat[['capacity_factor', 'generation_gwh']]\n",
    "iso = IsolationForest(max_samples='auto',contamination='auto')\n",
    "yhat = iso.fit_predict(df_all_concat_remove_outliers)\n",
    "# select all rows that are outliers\n",
    "mask = yhat == -1\n",
    "index_outliers = df_all_concat[mask].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_concat.loc[mask,['generation_gwh', 'capacity_mw']]\n",
    "sns.scatterplot(data=df_all_concat.loc[mask,['capacity_factor', 'capacity_mw']], x=\"capacity_factor\", y=\"capacity_mw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df_all_concat.loc[:,['capacity_factor', 'capacity_mw']].drop(index_outliers, axis=0), x=\"capacity_factor\", y=\"capacity_mw\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_concat[df_all_concat.loc[:,['name','generation_gwh', 'capacity_mw']].drop(index_outliers, axis=0)['name'].str.contains('CSP')]\n",
    "# df_all_concat.loc[:,['name','generation_gwh', 'capacity_mw']].drop(index_outliers, axis=0)['name'].str.contains('CSP')\n",
    "# df_all_concat.loc[~df_all_concat.drop(index_outliers, axis=0)['name'].str.contains('CSP')]\n",
    "# data = df_all_concat.drop(index_outliers, axis=0).loc[df_all_concat.drop(index_outliers, axis=0)['name'].str.contains('CSP')]\n",
    "# sns.scatterplot(data=data, x=\"generation_gwh\", y=\"capacity_mw\")\n",
    "# df_all_concat.loc[:,['name','generation_gwh', 'capacity_mw']].drop(index_outliers, axis=0)['name']\n",
    "# df_wind = df_wind[~df_wind['name'].str.contains('CSP')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df_all_concat.loc[:,['capacity_factor', 'capacity_mw']], x=\"capacity_factor\", y=\"capacity_mw\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_concat.drop(index_outliers, axis=0, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_concat.drop(columns=['capacity_factor'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_concat.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STATSMODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_all_concat.drop(columns=['generation_gwh'])\n",
    "# X = df_wind_2[['generation_gwh']]\n",
    "y = df_all_concat['generation_gwh']\n",
    "\n",
    "X = X.reindex(sorted(X.columns), axis=1)\n",
    "X_train_sm, X_test_sm, y_train_sm, y_test_sm = train_test_split(X, y, test_size=0.2,random_state = 0)\n",
    "\n",
    "X_train_sm = sm.add_constant(X_train_sm)\n",
    "model = sm.OLS(y_train_sm,X_train_sm)\n",
    "results = model.fit()\n",
    "\n",
    "print(f\"ECM: {results.mse_resid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INDIVIDUAL SIGNIFICANCE\n",
    "results.pvalues.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OVERALL SIGNIFICANCE\n",
    "results.f_pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.rsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.rsquared_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos la funcion coef_summary a los results\n",
    "\n",
    "coef_df = coef_summary(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los p-valor\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "coef_df = coef_df.sort_values(by='P>|t|', ascending = False)\n",
    "ax = sns.barplot(x='variables', y='P>|t|', data=coef_df,\n",
    "                 palette=\"Spectral\")\n",
    "ax.set_title('P-values', fontweight='bold', fontsize=20, y=1.1)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.grid(axis='y', linestyle='--')\n",
    "ax.set_ylabel('P-value', fontsize=10)\n",
    "ax.set_xlabel('variables', fontsize=10)\n",
    "plt.xticks(rotation=90, fontsize = 10 )\n",
    "plt.yticks( fontsize = 10 )\n",
    "plt.axhline(y = 0.05, color = 'black', linestyle = '--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCALED\n",
    "\n",
    "X = df_all_concat.drop(columns=['generation_gwh'])\n",
    "# X = df_wind_2[['generation_gwh']]\n",
    "y = df_all_concat['generation_gwh']\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "power_transformer = PowerTransformer(method='yeo-johnson')\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "\n",
    "x_scaled = min_max_scaler.fit_transform(X)\n",
    "# x_scaled = power_transformer.fit_transform(X)\n",
    "# x_scaled = standard_scaler.fit_transform(X)\n",
    "df_X_scaled = pd.DataFrame(x_scaled, index=X.index, columns=X.columns)\n",
    "df_all_concat_scaled = pd.concat([df_X_scaled,y], axis=1)\n",
    "df_all_concat_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_all_concat_scaled.drop(columns=['generation_gwh'])\n",
    "# X = df_wind_2[['generation_gwh']]\n",
    "y = df_all_concat_scaled['generation_gwh']\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "model_scaled = sm.OLS(y,X)\n",
    "results_scaled = model_scaled.fit()\n",
    "# Error Cuadratico Medio de los Residuos\n",
    "print(f\"ECM: {results_scaled.mse_resid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_scaled.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df_scaled = coef_summary(results_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los p-valor\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "coef_df_scaled = coef_df_scaled.sort_values(by='P>|t|', ascending = False)\n",
    "ax = sns.barplot(x='variables', y='P>|t|', data=coef_df_scaled,\n",
    "                 palette=\"Spectral\")\n",
    "ax.set_title('P-valor de los regresores', fontweight='bold', fontsize=20, y=1.1)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.grid(axis='y', linestyle='--')\n",
    "ax.set_ylabel('P-valor', fontsize=10)\n",
    "ax.set_xlabel('variables', fontsize=10)\n",
    "plt.xticks(rotation=90, fontsize = 10 )\n",
    "plt.yticks( fontsize = 10 )\n",
    "plt.axhline(y = 0.05, color = 'black', linestyle = '--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE Scaled: {results_scaled.rsquared}\",'vs.',f\"MSE: {results.rsquared}\" )\n",
    "print(f\"Adj MSE Scaled: {results_scaled.rsquared_adj}\",'vs.',f\" Adj MSE: {results.rsquared_adj}\" )\n",
    "print(f\"p-value Scaled: {results_scaled.f_pvalue}\",'vs.',f\" p-value: {results.f_pvalue}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORRELATION AND MUTUAL INFORMATION SCORES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avoid Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df_all_concat.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "\n",
    "try:\n",
    "    to_drop.remove('capacity_mw')\n",
    "except ValueError:\n",
    "    pass  # do nothing!\n",
    "try:\n",
    "    to_drop.remove('generation_gwh')\n",
    "except ValueError:\n",
    "    pass  # do nothing!\n",
    "\n",
    "df_all_concat.drop(columns=to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Best K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_scores = utils.make_mi_scores(df_all_concat.drop(columns=['generation_gwh']), df_all_concat[['generation_gwh']], \"regression\")\n",
    "\n",
    "plt.figure(figsize=(30,20))\n",
    "utils.plot_scores(mi_scores, \"Mutual Information Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_all_concat.drop(columns=['generation_gwh'])\n",
    "# X = df_all_concat[['generation_gwh']]\n",
    "y = df_all_concat['generation_gwh']\n",
    "# y\n",
    "selector = SelectKBest(mutual_info_regression, k= 10)\n",
    "new_X = selector.fit_transform(X, y)\n",
    "cols = selector.get_support(indices=True)\n",
    "features_df_new = X.iloc[:,cols]\n",
    "\n",
    "# # df_new_X = pd.DataFrame(new_X, index=new_X.index, columns=new_X.columns)\n",
    "df_all_concat_best_k_mi = pd.concat([features_df_new,y], axis=1)\n",
    "# df_all_concat_best_k_mi\n",
    "# selector.scores_\n",
    "# utils.plot_scores(selector.scores_, \"Best K\")\n",
    "# plt.plot(selector.scores_)\n",
    "# plt.xticks(np.arange(df_all_concat.drop(columns=['generation_gwh']).columns.len), list(df_all_concat.drop(columns=['generation_gwh']).columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Linear Correlations (Pearson) > 0.30 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib.pyplot import xlabel\n",
    "\n",
    "\n",
    "# plt.bar(df_all_concat.corr().abs().unstack()['capacity_mw'].sort_values(ascending=False), height=df_all_concat.columns)\n",
    "corr_matrix = df_all_concat.corr().abs()\n",
    "\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "target_correlations = corr_matrix.unstack()['generation_gwh'].sort_values(ascending=False)\n",
    "# target_correlations = corr_matrix.unstack()['generation_gwh'].sort_values(ascending=False)\n",
    "# target_correlations[target_correlations > .20]\n",
    "plt.figure(figsize=(20,10))\n",
    "# plt.figure(dpi=100, figsize=(4, 10))\n",
    "utils.plot_scores(target_correlations[target_correlations > .20], \"Correlations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_concat_lin_corr = df_all_concat[target_correlations[target_correlations > .20].index]\n",
    "df_all_concat_lin_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_concat_lin_corr.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annual Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_wind_2 = df_wind_2[(df_wind_2['capacity_mw'] < 100)].copy()\n",
    "\n",
    "columns_keep = df_all_concat.columns.str.contains('generation_gwh') | df_all_concat.columns.str.contains('ANN') | df_all_concat.columns.str.contains('capacity_mw')\n",
    "df_all_concat_annual = df_all_concat.loc[:,columns_keep]\n",
    "\n",
    "corr_matrix = df_all_concat_annual.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "# Find index of feature columns with correlation greater than 0.95\n",
    "# to_drop = [column for column in upper.columns if any(upper[column] > 0.98)]\n",
    "# df_all_concat_annual.drop(columns=to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_scores = utils.make_mi_scores(df_all_concat_annual.drop(columns=['generation_gwh']), df_all_concat_annual[['generation_gwh']], \"regression\")\n",
    "\n",
    "plt.figure(figsize=(30,20))\n",
    "utils.plot_scores(mi_scores, \"Mutual Information Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annual Best K (Mutual Information) Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_concat_annual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_all_concat_annual.drop(columns=['generation_gwh'])\n",
    "# # X = df_all_concat_annual[['generation_gwh']]\n",
    "# y = df_all_concat_annual['generation_gwh']\n",
    "# # y\n",
    "# selector = SelectKBest(mutual_info_regression, k= 10)\n",
    "# new_X = selector.fit_transform(X, y)\n",
    "# cols = selector.get_support(indices=True)\n",
    "# features_df_new = X.iloc[:,cols]\n",
    "\n",
    "# # # df_new_X = pd.DataFrame(new_X, index=new_X.index, columns=new_X.columns)\n",
    "# df_all_concat_annual_best_k_mi = pd.concat([features_df_new,y], axis=1)\n",
    "# # df_all_concat_annual_best_k_mi\n",
    "# # selector.scores_\n",
    "# # utils.plot_scores(selector.scores_, \"Best K\")\n",
    "# # plt.plot(selector.scores_)\n",
    "# # plt.xticks(np.arange(df_all_concat_annual.drop(columns=['generation_gwh']).columns.len), list(df_all_concat_annual.drop(columns=['generation_gwh']).columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_concat_annual_best_k_mi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annual Linear Correlations (Pearson) > 0.30 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import xlabel\n",
    "\n",
    "\n",
    "# plt.bar(df_all_concat_annual.corr().abs().unstack()['capacity_mw'].sort_values(ascending=False), height=df_all_concat_annual.columns)\n",
    "corr_matrix = df_all_concat_annual.corr().abs()\n",
    "\n",
    "\n",
    "\n",
    "target_correlations = corr_matrix.unstack()['generation_gwh'].sort_values(ascending=False)\n",
    "# target_correlations = corr_matrix.unstack()['generation_gwh'].sort_values(ascending=False)\n",
    "# target_correlations[target_correlations > .30]\n",
    "plt.figure(figsize=(20,10))\n",
    "# plt.figure(dpi=100, figsize=(4, 10))\n",
    "utils.plot_scores(target_correlations[target_correlations > .20], \"Correlations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_concat_annual_lin_corr = df_all_concat_annual[target_correlations[target_correlations > .20].index]\n",
    "df_all_concat_annual_lin_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = sns.PairGrid(df_all_concat_annual_lin_corr)\n",
    "# g.map(sns.scatterplot)\n",
    "\n",
    "# sns.pairplot(df_all_concat_annual_lin_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capacity and Shortwave Down features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_keep = df_all_concat.columns.str.contains('generation_gwh') | df_all_concat.columns.str.contains('SW_DWN') | df_all_concat.columns.str.contains('capacity_mw') | df_all_concat.columns.str.contains('capacity_factor')\n",
    "# df_all_concat_capacity_shortwave_down = df_all_concat.loc[:,columns_keep]\n",
    "# df_all_concat_capacity_shortwave_down\n",
    "# sns.pairplot(df_all_concat_capacity_shortwave_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(df_all_concat_capacity_shortwave_down)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only Capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_keep = df_all_concat.columns.str.contains('generation_gwh') | df_all_concat.columns.str.contains('capacity_mw')\n",
    "df_all_concat_only_capacity = df_all_concat.loc[:,columns_keep]\n",
    "df_all_concat_only_capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.qcut(df_all_concat['capacity_mw'], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = pd.qcut(df_all_concat['capacity_mw'], 4).cat.codes.rename('category')\n",
    "# category = pd.cut(df_all_concat['capacity_mw'], 6).cat.codes.rename('category')\n",
    "df_all_concat_w_category = pd.concat([df_all_concat, category], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_all_concat_w_category, hue='category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X AND Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_dict_X_y = {\n",
    "    'df_all_concat_annual_lin_corr' : {},\n",
    "    # 'df_all_concat_annual_best_k_mi': {},\n",
    "    'df_all_concat_lin_corr': {},\n",
    "    'df_all_concat_best_k_mi': {},\n",
    "    'df_all_concat': {},\n",
    "    # 'df_all_concat_capacity_shortwave_down': {},\n",
    "    'df_all_concat_only_capacity': {}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_df_all_concat_annual_lin_corr = IsolationForest(max_samples='auto',contamination='auto')\n",
    "yhat = iso_df_all_concat_annual_lin_corr.fit_predict(df_all_concat_annual_lin_corr)\n",
    "# select all rows that are outliers\n",
    "mask = yhat == -1\n",
    "index_outliers = df_all_concat_annual_lin_corr[mask].index\n",
    "df_all_concat_annual_lin_corr.drop(index_outliers, axis=0, inplace =True)\n",
    "\n",
    "X = df_all_concat_annual_lin_corr.drop(columns=['generation_gwh'])\n",
    "X = X.reindex(sorted(X.columns), axis=1)\n",
    "# X = df_all_concat_annual_lin_corr[['capacity_mw']]\n",
    "y = df_all_concat_annual_lin_corr['generation_gwh']\n",
    "\n",
    "\n",
    "\n",
    "dataframes_dict_X_y['df_all_concat_annual_lin_corr']['X'] = X\n",
    "dataframes_dict_X_y['df_all_concat_annual_lin_corr']['y'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_df_all_concat_lin_corr = IsolationForest(max_samples='auto',contamination='auto')\n",
    "yhat = iso_df_all_concat_lin_corr.fit_predict(df_all_concat_lin_corr)\n",
    "# select all rows that are outliers\n",
    "mask = yhat == -1\n",
    "index_outliers = df_all_concat_lin_corr[mask].index\n",
    "df_all_concat_lin_corr.drop(index_outliers, axis=0, inplace =True)\n",
    "\n",
    "\n",
    "X = df_all_concat_lin_corr.drop(columns=['generation_gwh'])\n",
    "X = X.reindex(sorted(X.columns), axis=1)\n",
    "# X = df_all_concat_lin_corr[['capacity_mw']]\n",
    "y = df_all_concat_lin_corr['generation_gwh']\n",
    "\n",
    "dataframes_dict_X_y['df_all_concat_lin_corr']['X'] = X\n",
    "dataframes_dict_X_y['df_all_concat_lin_corr']['y'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_all_concat_w_category.drop(columns=['generation_gwh'])\n",
    "# # X = df_wind_2[['capacity_mw']]\n",
    "# y = df_all_concat_w_category['generation_gwh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iso_df_all_concat_annual_best_k_mi = IsolationForest(max_samples='auto',contamination='auto')\n",
    "# yhat = iso_df_all_concat_annual_best_k_mi.fit_predict(df_all_concat_annual_best_k_mi)\n",
    "# # select all rows that are outliers\n",
    "# mask = yhat == -1\n",
    "# index_outliers = df_all_concat_annual_best_k_mi[mask].index\n",
    "# df_all_concat_annual_best_k_mi.drop(index_outliers, axis=0, inplace =True)\n",
    "\n",
    "\n",
    "# X = df_all_concat_annual_best_k_mi.drop(columns=['generation_gwh'])\n",
    "# X = X.reindex(sorted(X.columns), axis=1)\n",
    "# # X = df_wind_2[['capacity_mw']]\n",
    "# y = df_all_concat_annual_best_k_mi['generation_gwh']\n",
    "\n",
    "\n",
    "# dataframes_dict_X_y['df_all_concat_annual_best_k_mi']['X'] = X\n",
    "# dataframes_dict_X_y['df_all_concat_annual_best_k_mi']['y'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_df_all_concat_best_k_mi = IsolationForest(max_samples='auto',contamination='auto')\n",
    "yhat = iso_df_all_concat_best_k_mi.fit_predict(df_all_concat_best_k_mi)\n",
    "# select all rows that are outliers\n",
    "mask = yhat == -1\n",
    "index_outliers = df_all_concat_best_k_mi[mask].index\n",
    "df_all_concat_best_k_mi.drop(index_outliers, axis=0, inplace =True)\n",
    "\n",
    "\n",
    "X = df_all_concat_best_k_mi.drop(columns=['generation_gwh'])\n",
    "X = X.reindex(sorted(X.columns), axis=1)\n",
    "# X = df_wind_2[['capacity_mw']]\n",
    "y = df_all_concat_best_k_mi['generation_gwh']\n",
    "\n",
    "\n",
    "dataframes_dict_X_y['df_all_concat_best_k_mi']['X'] = X\n",
    "dataframes_dict_X_y['df_all_concat_best_k_mi']['y'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_df_all_concat = IsolationForest(max_samples='auto',contamination='auto')\n",
    "yhat = iso_df_all_concat.fit_predict(df_all_concat)\n",
    "# select all rows that are outliers\n",
    "mask = yhat == -1\n",
    "index_outliers = df_all_concat[mask].index\n",
    "df_all_concat.drop(index_outliers, axis=0, inplace =True)\n",
    "\n",
    "X = df_all_concat.drop(columns=['generation_gwh'])\n",
    "X = X.reindex(sorted(X.columns), axis=1)\n",
    "# X = df_all_concat[['capacity_mw']]\n",
    "y = df_all_concat['generation_gwh']\n",
    "\n",
    "\n",
    "dataframes_dict_X_y['df_all_concat']['X'] = X\n",
    "dataframes_dict_X_y['df_all_concat']['y'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_all_concat_only_capacity[['capacity_mw']]\n",
    "X.reindex(sorted(X.columns), axis=1)\n",
    "# X = df_all_concat_only_capacity[['capacity_mw']]\n",
    "y = df_all_concat_only_capacity['generation_gwh']\n",
    "\n",
    "dataframes_dict_X_y['df_all_concat_only_capacity']['X'] = X\n",
    "dataframes_dict_X_y['df_all_concat_only_capacity']['y'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_all_concat_only_capacity_and_factor[['capacity_mw']]\n",
    "# X.reindex(sorted(X.columns), axis=1)\n",
    "# # X = df_all_concat_only_capacity_and_factor[['capacity_mw']]\n",
    "# y = df_all_concat_only_capacity_and_factor['generation_gwh']\n",
    "\n",
    "# dataframes_dict_X_y['df_all_concat_only_capacity_and_factor']['X'] = X\n",
    "# dataframes_dict_X_y['df_all_concat_only_capacity_and_factor']['y'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iso_df_all_concat_capacity_shortwave_down = IsolationForest(max_samples='auto',contamination='auto')\n",
    "# yhat = iso_df_all_concat_capacity_shortwave_down.fit_predict(df_all_concat_capacity_shortwave_down)\n",
    "# # select all rows that are outliers\n",
    "# mask = yhat == -1\n",
    "# index_outliers = df_all_concat_capacity_shortwave_down[mask].index\n",
    "# df_all_concat_capacity_shortwave_down.drop(index_outliers, axis=0, inplace =True)\n",
    "\n",
    "# X = df_all_concat_capacity_shortwave_down.drop(columns=['generation_gwh'])\n",
    "# X = X.reindex(sorted(X.columns), axis=1)\n",
    "# # X = df_all_concat_capacity_shortwave_down[['capacity_mw']]\n",
    "# y = df_all_concat_capacity_shortwave_down['generation_gwh']\n",
    "\n",
    "\n",
    "# dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['X'] = X\n",
    "# dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['y'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_all_concat_scaled.drop(columns=['generation_gwh'])\n",
    "# # X = df_all_concat_scaled[['capacity_mw']]\n",
    "# y = df_all_concat_scaled['generation_gwh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del dataframes_dict_X_y['df_all_concat_only_capacity']\n",
    "# dataframes_dict_X_y['df_all_concat_capacity_shortwave_down'] = {}\n",
    "# dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['X'] = X\n",
    "# dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['y'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df_X_y in dataframes_dict_X_y.items():\n",
    "    list_train_test_split = train_test_split(df_X_y['X'], df_X_y['y'], test_size=0.2,random_state = 0)\n",
    "    dataframes_dict_X_y[i]['X_train'] = list_train_test_split[0]\n",
    "    dataframes_dict_X_y[i]['X_test'] = list_train_test_split[1]\n",
    "    dataframes_dict_X_y[i]['y_train'] = list_train_test_split[2]\n",
    "    dataframes_dict_X_y[i]['y_test'] = list_train_test_split[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_all = X_all.reindex(sorted(X.columns), axis=1)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2,random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECISION TREE REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_max_leaf_nodes = [2, 3, 4, 5, 7, 10, 50, 80, 100, 500, 1200, 1500]\n",
    "# candidate_max_leaf_nodes = [2, 3, 4, 5, 7, 10]\n",
    "\n",
    "# plt.figure(figsize=(25,15))\n",
    "fig, ax =plt.subplots(1,len(dataframes_dict_X_y), figsize=(25,5))\n",
    "for i, (k, df_X_y) in enumerate(dataframes_dict_X_y.items()):\n",
    "    results = {}\n",
    "    results = {node: utils.get_accuracy_tree(\"regression\",node, df_X_y['X_train'], df_X_y['X_test'], df_X_y['y_train'], df_X_y['y_test']) for node in candidate_max_leaf_nodes}\n",
    "    best_tree_size = max(results, key=results.get)\n",
    "    print(f'{k} best_tree_size: {best_tree_size}')\n",
    "    dataframes_dict_X_y[k]['best_tree_size'] = best_tree_size\n",
    "    ax[i].set_title(k)\n",
    "    sns.lineplot(data=results, x= results.keys(), y= results.values(), ax=ax[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (k, df_X_y) in enumerate(dataframes_dict_X_y.items()):\n",
    "    validation_curve_plot(k, DecisionTreeRegressor(), df_X_y['X_train'], df_X_y['y_train'], 'max_leaf_nodes', np.array(candidate_max_leaf_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (k, df_X_y) in enumerate(dataframes_dict_X_y.items()):\n",
    "    learning_curve_plot(k, DecisionTreeRegressor(max_leaf_nodes=50),df_X_y['X_train'], df_X_y['y_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (k, df_X_y) in enumerate(dataframes_dict_X_y.items()):\n",
    "    results = performance_metrics_cross_val(df_X_y['X_train'], df_X_y['y_train'], DecisionTreeRegressor(max_leaf_nodes=50), k)\n",
    "    print(k)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax =plt.subplots(2,len(dataframes_dict_X_y), figsize=(30,10))\n",
    "\n",
    "for i, (k, df_X_y) in enumerate(dataframes_dict_X_y.items()):\n",
    "    predicted = cross_val_predict(DecisionTreeRegressor(max_leaf_nodes=50), df_X_y['X_train'], df_X_y['y_train'], cv=5)\n",
    "    # fig, ax = plt.subplots()\n",
    "    ax[0,i].scatter(df_X_y['y_train'], predicted, edgecolors=(0, 0, 0))\n",
    "    ax[0,i].plot([df_X_y['y_train'].min(), df_X_y['y_train'].max()], [df_X_y['y_train'].min(), df_X_y['y_train'].max()], \"k--\", lw=4)\n",
    "    ax[0,i].set_xlabel(\"Measured\")\n",
    "    ax[0,i].set_ylabel(\"Predicted\")\n",
    "    ax[0,i].set_title(k)\n",
    "    # plt.show()\n",
    "\n",
    "    residuals = df_X_y['y_train'] - predicted\n",
    "    sns.scatterplot(x=df_X_y['y_train'], y=residuals, ax=ax[1, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model. Specify a number for random_state to ensure same results each run\n",
    "tree_model = DecisionTreeRegressor(max_leaf_nodes = 50)\n",
    "\n",
    "# Fit model\n",
    "tree_model.fit(dataframes_dict_X_y['df_all_concat_annual_best_k_mi']['X_train'], dataframes_dict_X_y['df_all_concat_annual_best_k_mi']['y_train'])\n",
    "y_pred = tree_model.predict(dataframes_dict_X_y['df_all_concat_annual_best_k_mi']['X_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numbers of trees\n",
    "n_estimators = [int(x) for x in np.arange(10, 101, 10)]\n",
    "# Numbers of features to consider at every split\n",
    "# max_features = [1, \"sqrt\", \"log2\"]\n",
    "# Maximum numbers of levels in tree\n",
    "max_depth = [int(x) for x in np.arange(10, 501, 10)]\n",
    "# Minimum numbers of samples required to split a node\n",
    "min_samples_split = [int(x) for x in np.arange(10, 51, 10)]\n",
    "# Minimum numbers of samples required at each leaf node\n",
    "min_samples_leaf = [int(x) for x in np.arange(5, 101, 5)]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "max_leaf_nodes = [int(x) for x in np.arange(10, 501, 10)]\n",
    "\n",
    "param_grid = {\n",
    "                'n_estimators': n_estimators,\n",
    "                # 'max_features': max_features,\n",
    "                'max_depth': max_depth,\n",
    "                'min_samples_split': min_samples_split,\n",
    "                'min_samples_leaf': min_samples_leaf,\n",
    "                'bootstrap': bootstrap,\n",
    "                'max_leaf_nodes': max_leaf_nodes\n",
    "            }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# rf_grid = GridSearchCV(estimator = RandomForestRegressor(), param_grid = param_grid, cv=5, verbose = 2, n_jobs=4)\n",
    "rf_grid = RandomizedSearchCV(estimator = RandomForestRegressor(), param_distributions = param_grid, n_iter = 40, cv=5, verbose = 2, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid.fit(dataframes_dict_X_y['df_all_concat_lin_corr']['X_train'], dataframes_dict_X_y['df_all_concat_lin_corr']['y_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid.score(dataframes_dict_X_y['df_all_concat_lin_corr']['X_test'], dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor(max_depth=220, max_leaf_nodes=280, min_samples_leaf=10,\n",
    "                      min_samples_split=40, n_estimators=70)\n",
    "# rf_model = RandomForestRegressor()\n",
    "for i, (k, df_X_y) in enumerate(dataframes_dict_X_y.items()):\n",
    "\n",
    "    # results = performance_metrics_cross_val(df_X_y['X_train'], df_X_y['y_train'], rf_grid.best_estimator_, k)\n",
    "    results = performance_metrics_cross_val(df_X_y['X_train'], df_X_y['y_train'], rf_model, k)\n",
    "    # print(df_X_y)\n",
    "    print(k)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax =plt.subplots(2,len(dataframes_dict_X_y), figsize=(30,10))\n",
    "\n",
    "for i, (k, df_X_y) in enumerate(dataframes_dict_X_y.items()):\n",
    "    # predicted = cross_val_predict(rf_grid.best_estimator_, df_X_y['X_train'], df_X_y['y_train'], cv=5)\n",
    "    predicted = cross_val_predict(rf_model, df_X_y['X_train'], df_X_y['y_train'], cv=5)\n",
    "    # fig, ax = plt.subplots()\n",
    "    ax[0,i].scatter(df_X_y['y_train'], predicted, edgecolors=(0, 0, 0))\n",
    "    ax[0,i].plot([df_X_y['y_train'].min(), df_X_y['y_train'].max()], [df_X_y['y_train'].min(), df_X_y['y_train'].max()], \"k--\", lw=4)\n",
    "    ax[0,i].set_xlabel(\"Measured\")\n",
    "    ax[0,i].set_ylabel(\"Predicted\")\n",
    "    ax[0,i].set_title(k)\n",
    "    # plt.show()\n",
    "    \n",
    "    residuals = df_X_y['y_train'] - predicted\n",
    "    dataframes_dict_X_y[k]['predictions'] = predicted\n",
    "    dataframes_dict_X_y[k]['residuals'] = residuals\n",
    "    sns.scatterplot(x=df_X_y['y_train'], y=residuals, ax=ax[1, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (k, df_X_y) in enumerate(dataframes_dict_X_y.items()):\n",
    "    learning_curve_plot(k, rf_model,df_X_y['X_train'], df_X_y['y_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = dataframes_dict_X_y['df_all_concat_lin_corr']['residuals'].reset_index()\n",
    "residuals_original = dataframes_dict_X_y['df_all_concat_lin_corr']['residuals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals[residuals == residuals.quantile(.05, interpolation='lower')].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowq = float(residuals['generation_gwh'][residuals['generation_gwh'] == residuals['generation_gwh'].quantile(.05, interpolation='lower')].values)\n",
    "lowq_index_pred = residuals[residuals['generation_gwh'] == residuals['generation_gwh'].quantile(.05, interpolation='lower')].index\n",
    "lowq_index = residuals[residuals['generation_gwh'] == residuals['generation_gwh'].quantile(.05, interpolation='lower')]['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "higq = float(residuals['generation_gwh'][residuals['generation_gwh'] == residuals['generation_gwh'].quantile(.95, interpolation='lower')].values)\n",
    "higq_index_pred = residuals[residuals['generation_gwh'] == residuals['generation_gwh'].quantile(.95, interpolation='lower')].index\n",
    "higq_index = residuals[residuals['generation_gwh'] == residuals['generation_gwh'].quantile(.95, interpolation='lower')]['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lowq) \n",
    "print(higq) \n",
    "print(lowq_index) \n",
    "print(higq_index) \n",
    "print(lowq_index_pred) \n",
    "print(higq_index_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframes_dict_X_y['df_all_concat_lin_corr']['predictions'][lowq_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the error distribution\n",
    "# resid_oob = dataframes_dict_X_y['df_all_concat_lin_corr']['y_train'] - rf_model_2.oob_prediction_\n",
    "# residuals = dataframes_dict_X_y['df_all_concat_lin_corr']['residuals']\n",
    "# residuals[residuals == residuals.quantile(.05, interpolation='lower')]\n",
    "# 50% interval\n",
    "lowq = residuals.quantile(0.05)\n",
    "# lowq_index = residuals.index(residuals.quantile(0.05))\n",
    "higq = residuals.quantile(0.95)\n",
    "# higq_index = residuals.index(residuals.quantile(0.95))\n",
    "print(lowq) \n",
    "print(higq) \n",
    "# negative much larger\n",
    "# so tends to overpredict time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating predictions on out of sample data\n",
    "y_pred = rf_model.predict(dataframes_dict_X_y['df_all_concat_lin_corr']['X_test'])\n",
    "lowt = (y_pred + lowq).clip(0) #cant have negative numbers\n",
    "higt = (y_pred + higq)\n",
    "\n",
    "cover = (dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'] >= lowt) & (dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'] <= higt)\n",
    "print(cover.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_dict_X_y['df_all_concat_lin_corr']['y_train'][lowq_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_dict_X_y['df_all_concat_lin_corr']['y_train'][lowq_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30, 15))\n",
    "# point1 = [0,0]\n",
    "# point2 = [dataframes_dict_X_y['df_all_concat_lin_corr']['y_train'][lowq_index].values, dataframes_dict_X_y['df_all_concat_lin_corr']['predictions'][lowq_index_pred]]\n",
    "# order = np.argsort(dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'].values)\n",
    "# plt.plot(dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'], f(dataframes_dict_X_y['df_all_concat_lin_corr']['y_test']), \"g:\", linewidth=3, label=r\"$f(x) = x\\,\\sin(x)$\")\n",
    "plt.plot(dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'].values,  y_pred, \"b.\", markersize=10, label=\"Test observations\")\n",
    "plt.plot(dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'].values,  lowt, \"r*\", markersize=10, label=\"\")\n",
    "plt.plot(dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'].values,  higt, \"k*\", markersize=10, label=\"\")\n",
    "# plt.plot(dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'].values, predictions['mid'], \"r-\", label=\"Predicted mean\")\n",
    "# plt.plot(dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'].values, predictions, \"r-\", label=\"Predicted mean\")\n",
    "# plt.plot([point1[0], point2[0]], [point1[1], point2[1]])\n",
    "# plt.plot(0, higq_oob, \"r*\")\n",
    "# plt.fill_between(\n",
    "#     dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'].values.ravel(), predictions['lower'], predictions['upper'], alpha=0.4, label=\"Predicted 90% interval\"\n",
    "# )\n",
    "# plt.xlabel(\"$x$\")\n",
    "# plt.ylabel(\"$f(x)$\")\n",
    "# plt.ylim(-10, 25)\n",
    "# plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_1 =dataframes_dict_X_y['df_all_concat_lin_corr']['X_test'].sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_1_modif = example_1.copy()\n",
    "\n",
    "example_1_modif\n",
    "# example_1_modif = example_1['capacity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_1_modif['capacity_mw'] = 20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = rf_model_2.predict(example_1_modif)\n",
    "print(mp)\n",
    "print( (mp-lowq).clip(0), (mp+higq) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LASSO, RIDGE, LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model = Lasso(alpha=0.01)\n",
    "lasso_model.fit(dataframes_dict_X_y['df_all_concat_lin_corr']['X_train'],dataframes_dict_X_y['df_all_concat_lin_corr']['y_train'])\n",
    "\n",
    "ridge_model = Ridge(alpha=1)\n",
    "ridge_model.fit(dataframes_dict_X_y['df_all_concat_lin_corr']['X_train'],dataframes_dict_X_y['df_all_concat_lin_corr']['y_train'])\n",
    "\n",
    "linreg_model = LinearRegression()\n",
    "linreg_model.fit(dataframes_dict_X_y['df_all_concat_lin_corr']['X_train'],dataframes_dict_X_y['df_all_concat_lin_corr']['y_train'])\n",
    "\n",
    "y_pred = lasso_model.predict(dataframes_dict_X_y['df_all_concat_lin_corr']['X_test'])\n",
    "print(\"Lasso\")\n",
    "print(mean_absolute_error(dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'], y_pred))\n",
    "print(mean_squared_error(dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'], y_pred))\n",
    "print(lasso_model.score(dataframes_dict_X_y['df_all_concat_lin_corr']['X_test'], dataframes_dict_X_y['df_all_concat_lin_corr']['y_test']))\n",
    "\n",
    "y_pred = linreg_model.predict(dataframes_dict_X_y['df_all_concat_lin_corr']['X_test'])\n",
    "print(\"Linear Regression\")\n",
    "print(mean_absolute_error(dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'], y_pred))\n",
    "print(mean_squared_error(dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'], y_pred))\n",
    "print(linreg_model.score(dataframes_dict_X_y['df_all_concat_lin_corr']['X_test'], dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'])\n",
    ")\n",
    "y_pred = ridge_model.predict(dataframes_dict_X_y['df_all_concat_lin_corr']['X_test'])\n",
    "print(\"Ridge\")\n",
    "print(mean_absolute_error(dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'], y_pred))\n",
    "print(mean_squared_error(dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'], y_pred))\n",
    "print(ridge_model.score(dataframes_dict_X_y['df_all_concat_lin_corr']['X_test'], dataframes_dict_X_y['df_all_concat_lin_corr']['y_test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(2,len(dataframes_dict_X_y), figsize=(30,10))\n",
    "\n",
    "for i, (k, df_X_y) in enumerate(dataframes_dict_X_y.items()):\n",
    "    predicted = cross_val_predict(Lasso(), df_X_y['X_train'], df_X_y['y_train'], cv=5)\n",
    "    # fig, ax = plt.subplots()\n",
    "    ax[0,i].scatter(df_X_y['y_train'], predicted, edgecolors=(0, 0, 0))\n",
    "    ax[0,i].plot([df_X_y['y_train'].min(), df_X_y['y_train'].max()], [df_X_y['y_train'].min(), df_X_y['y_train'].max()], \"k--\", lw=4)\n",
    "    ax[0,i].set_xlabel(\"Measured\")\n",
    "    ax[0,i].set_ylabel(\"Predicted\")\n",
    "    ax[0,i].set_title(k)\n",
    "    # plt.show()\n",
    "\n",
    "    residuals = df_X_y['y_train'] - predicted\n",
    "    sns.scatterplot(x=df_X_y['y_train'], y=residuals, ax=ax[1, i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(2,len(dataframes_dict_X_y), figsize=(30,10))\n",
    "\n",
    "for i, (k, df_X_y) in enumerate(dataframes_dict_X_y.items()):\n",
    "    predicted = cross_val_predict(Ridge(), df_X_y['X_train'], df_X_y['y_train'], cv=5)\n",
    "    # fig, ax = plt.subplots()\n",
    "    ax[0,i].scatter(df_X_y['y_train'], predicted, edgecolors=(0, 0, 0))\n",
    "    ax[0,i].plot([df_X_y['y_train'].min(), df_X_y['y_train'].max()], [df_X_y['y_train'].min(), df_X_y['y_train'].max()], \"k--\", lw=4)\n",
    "    ax[0,i].set_xlabel(\"Measured\")\n",
    "    ax[0,i].set_ylabel(\"Predicted\")\n",
    "    ax[0,i].set_title(k)\n",
    "    # plt.show()\n",
    "\n",
    "    residuals = df_X_y['y_train'] - predicted\n",
    "    sns.scatterplot(x=df_X_y['y_train'], y=residuals, ax=ax[1, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(2,len(dataframes_dict_X_y), figsize=(30,10))\n",
    "\n",
    "for i, (k, df_X_y) in enumerate(dataframes_dict_X_y.items()):\n",
    "    predicted = cross_val_predict(LinearRegression(), df_X_y['X_train'], df_X_y['y_train'], cv=5)\n",
    "    # fig, ax = plt.subplots()\n",
    "    ax[0,i].scatter(df_X_y['y_train'], predicted, edgecolors=(0, 0, 0))\n",
    "    ax[0,i].plot([df_X_y['y_train'].min(), df_X_y['y_train'].max()], [df_X_y['y_train'].min(), df_X_y['y_train'].max()], \"k--\", lw=4)\n",
    "    ax[0,i].set_xlabel(\"Measured\")\n",
    "    ax[0,i].set_ylabel(\"Predicted\")\n",
    "    ax[0,i].set_title(k)\n",
    "    # plt.show()\n",
    "\n",
    "    residuals = df_X_y['y_train'] - predicted\n",
    "    sns.scatterplot(x=df_X_y['y_train'], y=residuals, ax=ax[1, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0.01, 1.01, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generamos 50 lambdas para evaluar los distintos escenarios\n",
    "n_alphas = 50\n",
    "alphas = np.logspace(1.5, 7.2, n_alphas)\n",
    "\n",
    "# Ajustamos  la regresion Lasso para los disntos valores de lambda que establecimos\n",
    "coefs = []\n",
    "for a in alphas:\n",
    "    lasso = Lasso(alpha=a, fit_intercept=False)\n",
    "    lasso.fit(dataframes_dict_X_y['df_all_concat_lin_corr']['X_train'], dataframes_dict_X_y['df_all_concat_lin_corr']['y_train'])\n",
    "    coefs.append(lasso.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graficamos como varian las variables cuando se aumenta el lambda\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "\n",
    "l1 = plt.plot(alphas, coefs,linewidth=2 )\n",
    "\n",
    "ax.set_title('Regularizacin Lasso', fontweight='bold', fontsize=20)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "ax.set_ylabel('coeficientes', fontsize=10)\n",
    "ax.set_xlabel('Log(lambda)', fontsize=10)\n",
    "\n",
    "plt.xticks(fontsize = 10 )\n",
    "plt.yticks( fontsize = 10 )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Nos quedamos con las variables que sobreviven al proceso de seleccin\n",
    "coeficientes = pd.DataFrame(coefs, columns =dataframes_dict_X_y['df_all_concat_lin_corr']['X_train'].columns)\n",
    "\n",
    "variables_importantes = coeficientes.loc[:,dataframes_dict_X_y['df_all_concat_lin_corr']['X_train'].columns[coeficientes.loc[45:].any().values]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Graficamos nuevamente\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "\n",
    "l1 = plt.plot(alphas, variables_importantes,linewidth=2 )\n",
    "\n",
    "ax.set_title('Regularizacin Lasso', fontweight='bold', fontsize=20)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.legend(coeficientes.columns, fontsize=10)\n",
    "ax.set_ylabel('coeficientes', fontsize=10)\n",
    "ax.set_xlabel('Log(lambda)', fontsize=10)\n",
    "\n",
    "plt.xticks(fontsize = 10 )\n",
    "plt.yticks( fontsize = 10 )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCALLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, (k, df_X_y) in enumerate(dataframes_dict_X_y.items()):    \n",
    "    # X_train_normalized = stats.boxcox(X_train)\n",
    "    x = df_X_y['X_train'].values #returns a numpy array\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    power_transformer = PowerTransformer(method='yeo-johnson')\n",
    "    standard_scaler = StandardScaler()\n",
    "    # x_scaled = min_max_scaler.fit_transform(x)\n",
    "    # x_scaled = power_transformer.fit_transform(x)\n",
    "    x_scaled = standard_scaler.fit_transform(x)\n",
    "    df_X_y['X_train_scaled'] = pd.DataFrame(x_scaled, index=df_X_y['X_train'].index, columns=df_X_y['X_train'].columns)\n",
    "\n",
    "    x = df_X_y['X_test'].values #returns a numpy array\n",
    "    # x_scaled = min_max_scaler.fit_transform(x)\n",
    "    # x_scaled = power_transformer.fit_transform(x)\n",
    "    x_scaled = standard_scaler.fit_transform(x)\n",
    "    df_X_y['X_test_scaled'] = pd.DataFrame(x_scaled, index=df_X_y['X_test'].index, columns=df_X_y['X_test'].columns)\n",
    "\n",
    "    x = df_X_y['X'].values #returns a numpy array\n",
    "    # x_scaled = min_max_scaler.fit_transform(x)\n",
    "    # x_scaled = power_transformer.fit_transform(x)\n",
    "    x_scaled = standard_scaler.fit_transform(x)\n",
    "    df_X_y['X_scaled'] = pd.DataFrame(x_scaled, index=df_X_y['X'].index, columns=df_X_y['X'].columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_n_neighbors = np.arange(1,31)\n",
    "\n",
    "# plt.figure(figsize=(25,15))\n",
    "fig, ax =plt.subplots(1,len(dataframes_dict_X_y), figsize=(15,5))\n",
    "for i, (k, df_X_y) in enumerate(dataframes_dict_X_y.items()):\n",
    "    results = {}\n",
    "    results = {node: utils.get_accuracy_knn(\"regression\",node, df_X_y['X_train_scaled'], df_X_y['X_test_scaled'], df_X_y['y_train'], df_X_y['y_test']) for node in candidate_n_neighbors}\n",
    "    best_n_neighbors = max(results, key=results.get)\n",
    "    print(f'{k} best_n_neighbors: {best_n_neighbors}')\n",
    "    dataframes_dict_X_y[k]['best_n_neighbors'] = best_tree_size\n",
    "    ax[i].set_title(k)\n",
    "    sns.lineplot(data=results, x= results.keys(), y= results.values(), ax=ax[i])\n",
    "\n",
    "# results = {}\n",
    "\n",
    "# # results = {n: utils.get_accuracy_knn(n, X_train_scaled_pca, X_test_scaled_pca, y_train, y_test) for n in candidate_n_neighbors}\n",
    "# results = {n: utils.get_accuracy_knn(\"regression\",n, X_train, X_test, y_train, y_test) for n in candidate_n_neighbors}\n",
    "# best_n_neighbors = max(results, key=results.get)\n",
    "# print(best_n_neighbors)\n",
    "# sns.lineplot(data=results, x= results.keys(), y= results.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POLYNOMIAL FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_features = PolynomialFeatures(2)\n",
    "polynomial_features.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scaled_poly_knn = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    PolynomialFeatures(2),\n",
    "    KNeighborsRegressor(n_neighbors = dataframes_dict_X_y['df_all_concat_lin_corr']['best_n_neighbors'])\n",
    ")\n",
    "\n",
    "model_scaled_poly_knn.fit(dataframes_dict_X_y['df_all_concat_lin_corr']['X_train'], dataframes_dict_X_y['df_all_concat_lin_corr']['y_train'])\n",
    "model_scaled_poly_knn.score(dataframes_dict_X_y['df_all_concat_lin_corr']['X_test'], dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'])\n",
    "y_pred = model_scaled_poly_knn.predict(dataframes_dict_X_y['df_all_concat_lin_corr']['X_test'])\n",
    "residuals = dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'] - y_pred\n",
    "# ap_residuals = np.abs(residuals) / y_test\n",
    "# lap_residuals = np.log(ap_residuals)\n",
    "\n",
    "y_pred = model_scaled_poly_knn.predict(dataframes_dict_X_y['df_all_concat_lin_corr']['X_test'])\n",
    "sns.scatterplot(dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'], residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cross_validate(KNeighborsRegressor(n_neighbors = 12), X, y, cv=5)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VALIDATION AND LEARNING CURVE\n",
    "https://scikit-learn.org/stable/modules/learning_curve.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (k, df_X_y) in enumerate(dataframes_dict_X_y.items()):\n",
    "    validation_curve_plot(k, KNeighborsRegressor(), df_X_y['X_train_scaled'], df_X_y['y_train'], 'n_neighbors', np.array(candidate_n_neighbors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_scores, test_scores = validation_curve(\n",
    "#     KNeighborsRegressor(),\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     param_name = \"n_neighbors\",\n",
    "#     param_range = candidate_n_neighbors,\n",
    "#     cv = 5\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(train_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# candidate_n_neighbors.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (k, df_X_y) in enumerate(dataframes_dict_X_y.items()):\n",
    "    validation_curve_plot(k, KNeighborsRegressor(), df_X_y['X_train'], df_X_y['y_train'], 'n_neighbors', np.array(candidate_n_neighbors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (k, df_X_y) in enumerate(dataframes_dict_X_y.items()):\n",
    "    learning_curve_plot(k, KNeighborsRegressor(n_neighbors=14),df_X_y['X_train'], df_X_y['y_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax =plt.subplots(2,len(dataframes_dict_X_y), figsize=(30,10))\n",
    "\n",
    "for i, (k, df_X_y) in enumerate(dataframes_dict_X_y.items()):\n",
    "    predicted = cross_val_predict(KNeighborsRegressor(n_neighbors=14), df_X_y['X_train_scaled'], df_X_y['y_train'], cv=5)\n",
    "    # fig, ax = plt.subplots()\n",
    "    ax[0,i].scatter(df_X_y['y_train'], predicted, edgecolors=(0, 0, 0))\n",
    "    ax[0,i].plot([df_X_y['y_train'].min(), df_X_y['y_train'].max()], [df_X_y['y_train'].min(), df_X_y['y_train'].max()], \"k--\", lw=4)\n",
    "    ax[0,i].set_xlabel(\"Measured\")\n",
    "    ax[0,i].set_ylabel(\"Predicted\")\n",
    "    ax[0,i].set_title(k)\n",
    "    # plt.show()\n",
    "\n",
    "    residuals = df_X_y['y_train'] - predicted\n",
    "    sns.scatterplot(x=df_X_y['y_train'], y=residuals, ax=ax[1, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax =plt.subplots(2,len(dataframes_dict_X_y), figsize=(30,10))\n",
    "\n",
    "for i, (k, df_X_y) in enumerate(dataframes_dict_X_y.items()):\n",
    "    predicted = cross_val_predict(KNeighborsRegressor(n_neighbors=14), df_X_y['X_train'], df_X_y['y_train'], cv=5)\n",
    "    # fig, ax = plt.subplots()\n",
    "    ax[0,i].scatter(df_X_y['y_train'], predicted, edgecolors=(0, 0, 0))\n",
    "    ax[0,i].plot([df_X_y['y_train'].min(), df_X_y['y_train'].max()], [df_X_y['y_train'].min(), df_X_y['y_train'].max()], \"k--\", lw=4)\n",
    "    ax[0,i].set_xlabel(\"Measured\")\n",
    "    ax[0,i].set_ylabel(\"Predicted\")\n",
    "    ax[0,i].set_title(k)\n",
    "    # plt.show()\n",
    "\n",
    "    residuals = df_X_y['y_train'] - predicted\n",
    "    sns.scatterplot(x=df_X_y['y_train'], y=residuals, ax=ax[1, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (k, df_X_y) in enumerate(dataframes_dict_X_y.items()):\n",
    "    # results = performance_metrics_cross_val(df_X_y['X_train'], df_X_y['y_train'], rf_grid.best_estimator_, k)\n",
    "    results = performance_metrics_cross_val(df_X_y['X_train_scaled'], df_X_y['y_train'], KNeighborsRegressor(n_neighbors = 14), k)\n",
    "    print(k)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsRegressor(n_neighbors = 14)\n",
    "knn_model.fit(dataframes_dict_X_y['df_all_concat_best_k_mi']['X_train'], dataframes_dict_X_y['df_all_concat_best_k_mi']['y_train'])\n",
    "y_pred = knn_model.predict(dataframes_dict_X_y['df_all_concat_best_k_mi']['X_test'])\n",
    "residuals = dataframes_dict_X_y['df_all_concat_best_k_mi']['y_test'] - y_pred\n",
    "# ap_residuals = np.abs(residuals) / y_test\n",
    "# lap_residuals = np.log(ap_residuals)\n",
    "adjusted_r2(dataframes_dict_X_y['df_all_concat_best_k_mi']['X_train'], dataframes_dict_X_y['df_all_concat_best_k_mi']['y_test'], y_pred)\n",
    "print(r2_score(dataframes_dict_X_y['df_all_concat_best_k_mi']['y_test'], y_pred))\n",
    "# y_pred = model_poly_knn.predict(X_test)\n",
    "sns.scatterplot(dataframes_dict_X_y['df_all_concat_best_k_mi']['y_test'], residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(mean_absolute_error(dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['y_test'], y_pred))\n",
    "print(mean_squared_error(dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['y_test'], y_pred))\n",
    "print(np.sqrt(mean_squared_error(dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['y_test'], y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTION INTERVALS\n",
    "https://mapie.readthedocs.io/en/latest/tutorial_regression.html\n",
    "https://andrewpwheeler.com/2022/02/04/prediction-intervals-for-random-forests/\n",
    "https://stats.stackexchange.com/questions/85560/shape-of-confidence-interval-for-predicted-values-in-linear-regression\n",
    "https://saattrupdan.github.io/2020-03-01-bootstrap-prediction/\n",
    "https://medium.com/@qucit/a-simple-technique-to-estimate-prediction-intervals-for-any-regression-model-2dd73f630bcb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intervals with Gradient Tree Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numbers of trees\n",
    "n_estimators = [int(x) for x in np.arange(10, 101, 10)]\n",
    "# Numbers of features to consider at every split\n",
    "# max_features = [1, \"sqrt\", \"log2\"]\n",
    "# Maximum numbers of levels in tree\n",
    "max_depth = [int(x) for x in np.arange(10, 501, 10)]\n",
    "# Minimum numbers of samples required to split a node\n",
    "min_samples_split = [int(x) for x in np.arange(10, 51, 10)]\n",
    "# Minimum numbers of samples required at each leaf node\n",
    "min_samples_leaf = [int(x) for x in np.arange(5, 101, 5)]\n",
    "# Method of selecting samples for training each tree\n",
    "# bootstrap = [True, False]\n",
    "\n",
    "max_leaf_nodes = [int(x) for x in np.arange(10, 501, 10)]\n",
    "\n",
    "learning_rate = [np.around(x,3) for x in np.arange(0.005, 2.001, 0.005)]\n",
    "\n",
    "param_grid = {\n",
    "                'n_estimators': n_estimators,\n",
    "                # 'max_features': max_features,\n",
    "                'max_depth': max_depth,\n",
    "                'min_samples_split': min_samples_split,\n",
    "                'min_samples_leaf': min_samples_leaf,\n",
    "                # 'bootstrap': bootstrap,\n",
    "                'max_leaf_nodes': max_leaf_nodes,\n",
    "                'learning_rate': learning_rate\n",
    "            }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_grid = RandomizedSearchCV(estimator = GradientBoostingRegressor(), param_distributions = param_grid, n_iter = 30, cv=5, verbose = 2, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_grid.fit(dataframes_dict_X_y['df_all_concat_lin_corr']['X_train'], dataframes_dict_X_y['df_all_concat_lin_corr']['y_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_grid.score(dataframes_dict_X_y['df_all_concat_lin_corr']['X_test'], dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOWER_ALPHA = 0.05\n",
    "UPPER_ALPHA = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_mean_pinball_loss_05p_scorer = make_scorer(\n",
    "    mean_pinball_loss,\n",
    "    alpha=LOWER_ALPHA,\n",
    "    greater_is_better=False,  # maximize the negative loss\n",
    ")\n",
    "neg_mean_pinball_loss_95p_scorer = make_scorer(\n",
    "    mean_pinball_loss,\n",
    "    alpha=UPPER_ALPHA,\n",
    "    greater_is_better=False,  # maximize the negative loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOWER_ALPHA = 0.05\n",
    "UPPER_ALPHA = 0.95\n",
    "\n",
    "param_grid_lower = param_grid.copy()\n",
    "# param_grid_lower['loss'] = 'quantile'\n",
    "# param_grid_lower['alpha'] = LOWER_ALPHA\n",
    "\n",
    "param_grid_upper = param_grid.copy()\n",
    "# param_grid_upper['loss'] = 'quantile'\n",
    "# param_grid_upper['alpha'] = UPPER_ALPHA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_grid_lower = RandomizedSearchCV(estimator = GradientBoostingRegressor(loss='quantile', alpha=LOWER_ALPHA), param_distributions = param_grid_lower, n_iter = 30, cv=5, verbose = 2, n_jobs=4, scoring=neg_mean_pinball_loss_05p_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_grid_lower.fit(dataframes_dict_X_y['df_all_concat_lin_corr']['X_train'], dataframes_dict_X_y['df_all_concat_lin_corr']['y_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_grid_lower.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_grid_lower.score(dataframes_dict_X_y['df_all_concat_lin_corr']['X_test'], dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_grid_upper = RandomizedSearchCV(estimator = GradientBoostingRegressor(loss='quantile', alpha=UPPER_ALPHA), param_distributions = param_grid_upper, n_iter = 30, cv=5, verbose = 2, n_jobs=4, scoring=neg_mean_pinball_loss_95p_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_grid_upper.fit(dataframes_dict_X_y['df_all_concat_lin_corr']['X_train'], dataframes_dict_X_y['df_all_concat_lin_corr']['y_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_grid_upper.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_grid_upper.score(dataframes_dict_X_y['df_all_concat_lin_corr']['X_test'], dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set lower and upper quantile\n",
    "\n",
    "\n",
    "# N_ESTIMATORS = 100\n",
    "# MAX_DEPTH = 5\n",
    "\n",
    "# Each model has to be separate\n",
    "GradientBoostingRegressor(alpha=0.05, learning_rate=0.385, loss='quantile',\n",
    "                          max_depth=260, max_leaf_nodes=430,\n",
    "                          min_samples_leaf=50, min_samples_split=20,\n",
    "                          n_estimators=60)\n",
    "lower_model = GradientBoostingRegressor(loss=\"quantile\", alpha=LOWER_ALPHA, learning_rate=0.245, max_depth=430,\n",
    "                          max_leaf_nodes=300, min_samples_leaf=10,\n",
    "                          min_samples_split=20, n_estimators=70)\n",
    "# The mid model will use the default\n",
    "# mid_model = GradientBoostingRegressor(learning_rate=0.245, max_depth=430,\n",
    "#                           max_leaf_nodes=300, min_samples_leaf=10,\n",
    "#                           min_samples_split=20, n_estimators=70)\n",
    "mean_model = GradientBoostingRegressor(learning_rate=0.245, max_depth=430,\n",
    "                          max_leaf_nodes=300, min_samples_leaf=10,\n",
    "                          min_samples_split=20, n_estimators=70)\n",
    "# mid_model = GradientBoostingRegressor(n_estimators=N_ESTIMATORS, max_depth=MAX_DEPTH)\n",
    "\n",
    "upper_model = GradientBoostingRegressor(alpha=0.95, learning_rate=0.155, loss='quantile',\n",
    "                          max_depth=350, max_leaf_nodes=320,\n",
    "                          min_samples_leaf=60, min_samples_split=30,\n",
    "                          n_estimators=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = lower_model.fit(dataframes_dict_X_y['df_all_concat_lin_corr']['X_train'], dataframes_dict_X_y['df_all_concat_lin_corr']['y_train'])\n",
    "_ = mean_model.fit(dataframes_dict_X_y['df_all_concat_lin_corr']['X_train'], dataframes_dict_X_y['df_all_concat_lin_corr']['y_train'])\n",
    "_ = upper_model.fit(dataframes_dict_X_y['df_all_concat_lin_corr']['X_train'], dataframes_dict_X_y['df_all_concat_lin_corr']['y_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'])\n",
    "predictions['lower'] = lower_model.predict(dataframes_dict_X_y['df_all_concat_lin_corr']['X_test'])\n",
    "predictions['mid'] = mean_model.predict(dataframes_dict_X_y['df_all_concat_lin_corr']['X_test'])\n",
    "predictions['upper'] = upper_model.predict(dataframes_dict_X_y['df_all_concat_lin_corr']['X_test'])\n",
    "predictions['mean'] = mean_model.predict(dataframes_dict_X_y['df_all_concat_lin_corr']['X_test'])\n",
    "\n",
    "\n",
    "# assert (predictions['upper'] > predictions['lower']).all()\n",
    "\n",
    "predictions.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['upper'] > predictions['lower']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[(predictions['lower'] > predictions['upper'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[(predictions['lower'] > predictions['mid'])].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[(predictions['mid'] > predictions['upper'])].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'][7491]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30, 15))\n",
    "\n",
    "# order = np.argsort(dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'].values)\n",
    "# plt.plot(dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'], f(dataframes_dict_X_y['df_all_concat_lin_corr']['y_test']), \"g:\", linewidth=3, label=r\"$f(x) = x\\,\\sin(x)$\")\n",
    "plt.plot(dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'].values,  predictions['mid'], \"b.\", markersize=10, label=\"Test observations\")\n",
    "# plt.plot(dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'].values, predictions['mid'], \"r-\", label=\"Predicted mean\")\n",
    "# plt.plot(dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'].values, predictions, \"r-\", label=\"Predicted mean\")\n",
    "plt.plot(dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'].values, predictions['upper'], \"k*\")\n",
    "plt.plot(dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'].values, predictions['lower'], \"r*\")\n",
    "# plt.fill_between(\n",
    "#     dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'].values.ravel(), predictions['lower'], predictions['upper'], alpha=0.4, label=\"Predicted 90% interval\"\n",
    "# )\n",
    "# plt.xlabel(\"$x$\")\n",
    "# plt.ylabel(\"$f(x)$\")\n",
    "# plt.ylim(-10, 25)\n",
    "# plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coverage_fraction(y, y_low, y_high):\n",
    "    return np.mean(np.logical_and(y >= y_low, y <= y_high))\n",
    "\n",
    "\n",
    "coverage_fraction(\n",
    "    dataframes_dict_X_y['df_all_concat_lin_corr']['y_train'],\n",
    "    lower_model.predict(dataframes_dict_X_y['df_all_concat_lin_corr']['X_train']),\n",
    "    upper_model.predict(dataframes_dict_X_y['df_all_concat_lin_corr']['X_train']),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'].values[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax =plt.subplots(2,len(dataframes_dict_X_y), figsize=(30,10))\n",
    "\n",
    "for i, (k, df_X_y) in enumerate(dataframes_dict_X_y.items()):\n",
    "    # predicted = cross_val_predict(rf_grid.best_estimator_, df_X_y['X_train'], df_X_y['y_train'], cv=5)\n",
    "    predicted = cross_val_predict(mid_model, df_X_y['X_train'], df_X_y['y_train'], cv=5)\n",
    "    # fig, ax = plt.subplots()\n",
    "    ax[0,i].scatter(df_X_y['y_train'], predicted, edgecolors=(0, 0, 0))\n",
    "    ax[0,i].plot([df_X_y['y_train'].min(), df_X_y['y_train'].max()], [df_X_y['y_train'].min(), df_X_y['y_train'].max()], \"k--\", lw=4)\n",
    "    ax[0,i].set_xlabel(\"Measured\")\n",
    "    ax[0,i].set_ylabel(\"Predicted\")\n",
    "    ax[0,i].set_title(k)\n",
    "    # plt.show()\n",
    "\n",
    "    residuals = df_X_y['y_train'] - predicted\n",
    "    sns.scatterplot(x=df_X_y['y_train'], y=residuals, ax=ax[1, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (k, df_X_y) in enumerate(dataframes_dict_X_y.items()):\n",
    "    learning_curve_plot(k, mid_model,df_X_y['X_train'], df_X_y['y_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = rf_grid.best_estimator_\n",
    "# XX, yy = make_regression(n_samples=500, n_features=1, noise=20, random_state=59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model.fit(dataframes_dict_X_y['df_all_concat_lin_corr']['X_train'], dataframes_dict_X_y['df_all_concat_lin_corr']['y_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_try = rf_model.predict(dataframes_dict_X_y['df_all_concat_lin_corr']['X_test'])\n",
    "\n",
    "predictions_try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intervals with Mapie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_1d_data(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    y_pred_low,\n",
    "    y_pred_up,\n",
    "    ax=None,\n",
    "    title=None\n",
    "):\n",
    "    fig, ax = plt.subplots(figsize=(10,7))\n",
    "    ax.set_xlabel(\"x\") ; ax.set_ylabel(\"y\")\n",
    "    # ax.fill_between(X_train, y_pred_low, y_pred_up, alpha=0.3)\n",
    "    ax.scatter(X_train, y_train, color=\"red\", alpha=0.3, label=\"Training data\")\n",
    "    ax.plot(X_train, y_pred_low, color=\"gray\", ls=\"--\", label=\"Lower\")\n",
    "    # ax.plot(X_test, y_test - y_sigma, color=\"gray\", ls=\"--\")\n",
    "    # ax.plot(X_test, y_test + y_sigma, color=\"gray\", ls=\"--\")\n",
    "    ax.plot(X_train, y_pred_up, color=\"blue\", ls=\"--\", alpha=0.5, label=\"Upper\")\n",
    "    ax.plot(X_train, X_train, color=\"black\", ls=\"-\", alpha=0.5, label=\"Real target\")\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "# mapie = MapieRegressor(rf_model, method=\"plus\", cv=5)\n",
    "# mapie = MapieRegressor(rf_model, method=\"naive\")\n",
    "# mapie = MapieRegressor(rf_model, method=\"base\", cv=-1)\n",
    "# mapie = MapieRegressor(rf_model, method=\"minmax\", cv=10)\n",
    "mapie = MapieRegressor(rf_model, method=\"base\", cv=5)\n",
    "mapie.fit(dataframes_dict_X_y['df_all_concat_lin_corr']['X_train'], dataframes_dict_X_y['df_all_concat_lin_corr']['y_train'])\n",
    "y_pred, y_pis = mapie.predict(dataframes_dict_X_y['df_all_concat_lin_corr']['X_test'], alpha=alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mapie = pd.DataFrame()\n",
    "df_mapie['y_pred'] = y_pred\n",
    "df_mapie['y_test'] = dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'].reset_index(drop=True)\n",
    "df_mapie['y_pis_lower'] = y_pis[:,0,:]\n",
    "df_mapie['y_pis_upper'] = y_pis[:,1,:]\n",
    "df_mapie_sorted = df_mapie.sort_values(by=['y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(10,7))\n",
    "\n",
    "# order = np.argsort(dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['y_test'].values)\n",
    "plot_1d_data(\n",
    "    df_mapie_sorted['y_test'],\n",
    "    df_mapie_sorted['y_pred'],\n",
    "    df_mapie_sorted['y_pis_lower'],\n",
    "    df_mapie_sorted['y_pis_upper'],\n",
    "    ax=None,\n",
    "    title=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "# mapie = MapieRegressor(rf_model, method=\"plus\", cv=5)\n",
    "# mapie.fit(dataframes_dict_X_y['df_all_concat_lin_corr']['X_train'], dataframes_dict_X_y['df_all_concat_lin_corr']['y_train'])\n",
    "# y_pred, y_pis = mapie.predict(dataframes_dict_X_y['df_all_concat_lin_corr']['X_test'], alpha=alpha)\n",
    "\n",
    "\n",
    "mapie = MapieQuantileRegressor(GradientBoostingRegressor(loss=\"quantile\", learning_rate=0.245, max_depth=430,\n",
    "                          max_leaf_nodes=300, min_samples_leaf=10,\n",
    "                          min_samples_split=20, n_estimators=70), method=\"quantile\", cv=\"split\", alpha=alpha)\n",
    "mapie.fit(dataframes_dict_X_y['df_all_concat_lin_corr']['X_train'], dataframes_dict_X_y['df_all_concat_lin_corr']['y_train'])\n",
    "y_pred, y_pis = mapie.predict(dataframes_dict_X_y['df_all_concat_lin_corr']['X_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mapie = pd.DataFrame()\n",
    "df_mapie['y_pred'] = y_pred\n",
    "df_mapie['y_test'] = dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'].reset_index(drop=True)\n",
    "df_mapie['y_pis_lower'] = y_pis[:,0,:]\n",
    "df_mapie['y_pis_upper'] = y_pis[:,1,:]\n",
    "df_mapie_sorted = df_mapie.sort_values(by=['y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_1d_data(\n",
    "    df_mapie_sorted['y_test'],\n",
    "    df_mapie_sorted['y_pred'],\n",
    "    df_mapie_sorted['y_pis_lower'],\n",
    "    df_mapie_sorted['y_pis_upper'],\n",
    "    ax=None,\n",
    "    title=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_scores = [\n",
    "    regression_coverage_score(dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['y_test'], y_pis[:, 0, i], y_pis[:, 1, i])\n",
    "    for i, _ in enumerate(alpha_sasa)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = np.argsort(XX[:, 0])\n",
    "# dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "order = np.argsort(XX[:, 0])\n",
    "plt.scatter(XX[order], y_pred_sasa[order], alpha=0.3)\n",
    "plt.plot(XX[order], y_pred_sasa[order], color=\"C1\")\n",
    "plt.plot(XX[order], y_pis[order][:, 0, 1], color=\"C1\", ls=\"--\")\n",
    "plt.plot(XX[order], y_pis[order][:, 1, 1], color=\"C1\", ls=\"--\")\n",
    "plt.fill_between(\n",
    "    XX[order].ravel(),\n",
    "    y_pis[order][:, 0, 0].ravel(),\n",
    "    y_pis[order][:, 1, 0].ravel(),\n",
    "    alpha=0.2\n",
    ")\n",
    "plt.title(\n",
    "    f\"Target and effective coverages for \"\n",
    "    f\"alpha={alpha_sasa[0]:.2f}: ({1-alpha_sasa[0]:.3f}, {coverage_scores[0]:.3f})\\n\"\n",
    "    f\"Target and effective coverages for \"\n",
    "    f\"alpha={alpha_sasa[1]:.2f}: ({1-alpha_sasa[1]:.3f}, {coverage_scores[1]:.3f})\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "lasso_model = Lasso(alpha=0.05)\n",
    "res = []\n",
    "estimators = []\n",
    "for train_index, test_index in kf.split(dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['X_train']):\n",
    "    # continue\n",
    "    # print(dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['X_train'].iloc[train_index])\n",
    "    X_train_, X_test_ = dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['X_train'].iloc[train_index], dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['X_train'].iloc[test_index]\n",
    "    y_train_, y_test_ = dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['y_train'].iloc[train_index], dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['y_train'].iloc[test_index]\n",
    "    \n",
    "    lasso_model.fit(X_train_, y_train_)\n",
    "    estimators.append(lasso_model)\n",
    "    res.extend(list(y_test_ - lasso_model.predict(X_test_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "order = np.argsort(dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['y_test'].values)\n",
    "plt.scatter(dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['y_test'].values[order], y_pred[order], alpha=0.3)\n",
    "plt.plot(dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['y_test'].values[order], y_pred[order], color=\"C1\")\n",
    "# plt.plot(dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['y_test'].values[order], y_pis[order][:, 0, 1], color=\"C1\", ls=\"--\")\n",
    "# plt.plot(dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['y_test'].values[order], y_pis[order][:, 1, 1], color=\"C1\", ls=\"--\")\n",
    "plt.fill_between(\n",
    "    dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['y_test'].values[order].ravel(),\n",
    "    y_pis[order][:, 0, 0].ravel(),\n",
    "    y_pis[order][:, 1, 0].ravel(),\n",
    "    alpha=0.2\n",
    ")\n",
    "# plt.title(\n",
    "#     f\"Target and effective coverages for \"\n",
    "#     f\"alpha={alpha[0]:.2f}: ({1-alpha[0]:.3f}, {coverage_scores[0]:.3f})\\n\"\n",
    "#     f\"Target and effective coverages for \"\n",
    "#     f\"alpha={alpha[1]:.2f}: ({1-alpha[1]:.3f}, {coverage_scores[1]:.3f})\"\n",
    "# )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "lasso_model = Lasso(alpha=0.05)\n",
    "res = []\n",
    "estimators = []\n",
    "for train_index, test_index in kf.split(dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['X_train']):\n",
    "    # continue\n",
    "    # print(dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['X_train'].iloc[train_index])\n",
    "    X_train_, X_test_ = dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['X_train'].iloc[train_index], dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['X_train'].iloc[test_index]\n",
    "    y_train_, y_test_ = dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['y_train'].iloc[train_index], dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['y_train'].iloc[test_index]\n",
    "    \n",
    "    knn_model.fit(X_train_, y_train_)\n",
    "    estimators.append(knn_model)\n",
    "    res.extend(list(y_test_ - knn_model.predict(X_test_)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_multi = np.column_stack([e.predict(dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['X_test']) for e in estimators])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "ci = np.quantile(res, 1 - alpha)\n",
    "top = []\n",
    "bottom = []\n",
    "for i in range(y_pred_multi.shape[0]):\n",
    "    if ci > 0:\n",
    "        top.append(np.quantile(y_pred_multi[i] + ci, 1 - alpha))\n",
    "        bottom.append(np.quantile(y_pred_multi[i] - ci, 1 - alpha))\n",
    "    else:\n",
    "        top.append(np.quantile(y_pred_multi[i] - ci, 1 - alpha))\n",
    "        bottom.append(np.quantile(y_pred_multi[i] + ci, 1 - alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.median(y_pred_multi, axis=1)\n",
    "df = pd.DataFrame()\n",
    "df['pred'] = preds\n",
    "df['upper'] = top\n",
    "df['lower'] = bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(['upper'], ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.sort_values(['pred'], ascending = False)\n",
    "df.iloc[702,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['y_test'].iloc[702]\n",
    "dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['y_test'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_plot_plus(y_test, preds, bottom, upper,):\n",
    "    \n",
    "    ci_pack = np.vstack([bottom, upper])\n",
    "    \n",
    "    plt.figure(figsize=(12,9))\n",
    "    plt.errorbar([i for i in range(len(preds))], preds, ci_pack, fmt='o', color='black', ecolor='lightgray')\n",
    "    plt.plot([i for i in range(len(y_test))], y_test, 'o', c='r')\n",
    "    plt.legend(['True Value', 'Prediction', 'Confidence Interval'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "order = np.argsort(dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['y_test'].values)\n",
    "# generate_plot_plus(dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['y_test'].values[order], df['pred'].values[order], df['lower'].values[order], df['upper'].values[order])\n",
    "generate_plot_plus(dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['y_test'], df['pred'], df['lower'], df['upper'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "order = np.argsort(dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['y_test'].values)\n",
    "ax.plot(dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['y_test'].values[order], df['pred'][order], color=\"C1\")\n",
    "ax.scatter(dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['y_test'].values[order],df['pred'].values[order])\n",
    "ax.fill_between(dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['y_test'].values[order], df['lower'].values[order].ravel(), df['upper'].values[order].ravel(), color='b', alpha=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.xlabel(\"x\")\n",
    "# plt.ylabel(\"y\")\n",
    "plt.scatter(dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['y_test'].values[order], df['pred'].values[order], alpha=0.3)\n",
    "plt.plot(dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['y_test'].values[order], df['pred'].values[order], color=\"C1\")\n",
    "# order = np.argsort(dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['X_test'][:, 0])\n",
    "# plt.plot(dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['X_test'][order], y_pis[order][:, 0, 1], color=\"C1\", ls=\"--\")\n",
    "# plt.plot(dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['X_test'][order], y_pis[order][:, 1, 1], color=\"C1\", ls=\"--\")\n",
    "plt.fill_between(\n",
    "    dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['y_test'].values[order].ravel(),\n",
    "    df['lower'].values[order].ravel(),\n",
    "    df['upper'].values[order].ravel(),\n",
    "    alpha=0.2\n",
    ")\n",
    "plt.title(\n",
    "    f\"Target and effective coverages for \"\n",
    "    f\"alpha={alpha[0]:.2f}: ({1-alpha[0]:.3f}, {coverage_scores[0]:.3f})\\n\"\n",
    "    f\"Target and effective coverages for \"\n",
    "    f\"alpha={alpha[1]:.2f}: ({1-alpha[1]:.3f}, {coverage_scores[1]:.3f})\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_dict_X_y['df_all_concat_annual_best_k_mi']['y_test'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantile Regressor on between y real values and y predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax =plt.subplots(2, figsize=(30,10))\n",
    "\n",
    "# for i, (k, df_X_y) in enumerate(dataframes_dict_X_y.items()):\n",
    "# predicted = cross_val_predict(rf_grid.best_estimator_, df_X_y['X_train'], df_X_y['y'], cv=5)\n",
    "predicted = cross_val_predict(knn_model, dataframes_dict_X_y['df_all_concat_lin_corr']['X'], dataframes_dict_X_y['df_all_concat_lin_corr']['y'], cv=5)\n",
    "# fig, ax = plt.subplots()\n",
    "ax[0].scatter(dataframes_dict_X_y['df_all_concat_lin_corr']['y'], predicted, edgecolors=(0, 0, 0))\n",
    "ax[0].plot([dataframes_dict_X_y['df_all_concat_lin_corr']['y'].min(), dataframes_dict_X_y['df_all_concat_lin_corr']['y'].max()], [dataframes_dict_X_y['df_all_concat_lin_corr']['y'].min(), dataframes_dict_X_y['df_all_concat_lin_corr']['y'].max()], \"k--\", lw=4)\n",
    "ax[0].set_xlabel(\"Measured\")\n",
    "ax[0].set_ylabel(\"Predicted\")\n",
    "ax[0].set_title(k)\n",
    "# plt.show()\n",
    "\n",
    "residuals = dataframes_dict_X_y['df_all_concat_lin_corr']['y'] - predicted\n",
    "dataframes_dict_X_y['df_all_concat_lin_corr']['predictions_all_data'] = predicted\n",
    "sns.scatterplot(x=dataframes_dict_X_y['df_all_concat_lin_corr']['y'], y=residuals, ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_dict_X_y['df_all_concat_lin_corr']['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = [0.05, 0.95]\n",
    "predictions_qr = {}\n",
    "# dataframes_dict_X_y['df_all_concat_lin_corr']['predictions_all_data']\n",
    "# dataframes_dict_X_y['df_all_concat_lin_corr']['y']\n",
    "out_bounds_predictions = np.zeros_like(dataframes_dict_X_y['df_all_concat_lin_corr']['y'].values, dtype=np.bool_)\n",
    "for quantile in quantiles:\n",
    "    qr = QuantileRegressor(quantile=quantile, fit_intercept= False, solver='highs', alpha=0)\n",
    "    qr.fit(dataframes_dict_X_y['df_all_concat_lin_corr']['predictions_all_data'].reshape(-1, 1), dataframes_dict_X_y['df_all_concat_lin_corr']['y'].values)\n",
    "    dataframes_dict_X_y['df_all_concat_lin_corr'][f'model_qr_{str(quantile)[2:]}_fit'] = qr\n",
    "    y_pred = qr.predict(dataframes_dict_X_y['df_all_concat_lin_corr']['predictions_all_data'].reshape(-1, 1))\n",
    "    predictions_qr[quantile] = y_pred\n",
    "\n",
    "    if quantile == min(quantiles):\n",
    "        out_bounds_predictions = np.logical_or(\n",
    "            out_bounds_predictions, y_pred >= dataframes_dict_X_y['df_all_concat_lin_corr']['y'].values\n",
    "        )\n",
    "    elif quantile == max(quantiles):\n",
    "        out_bounds_predictions = np.logical_or(\n",
    "            out_bounds_predictions, y_pred <= dataframes_dict_X_y['df_all_concat_lin_corr']['y'].values\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "# dataframes_dict_X_y['df_all_concat_lin_corr']['predictions_all_data']\n",
    "# dataframes_dict_X_y['df_all_concat_lin_corr']['y']\n",
    "\n",
    "plt.plot(dataframes_dict_X_y['df_all_concat_lin_corr']['predictions_all_data'], dataframes_dict_X_y['df_all_concat_lin_corr']['predictions_all_data'], color=\"black\", linestyle=\"dashed\", label=\"True mean\")\n",
    "\n",
    "for quantile, y_pred in predictions_qr.items():\n",
    "    plt.plot(dataframes_dict_X_y['df_all_concat_lin_corr']['predictions_all_data'], y_pred, label=f\"Quantile: {quantile}\")\n",
    "\n",
    "plt.scatter(\n",
    "    dataframes_dict_X_y['df_all_concat_lin_corr']['predictions_all_data'][out_bounds_predictions],\n",
    "    dataframes_dict_X_y['df_all_concat_lin_corr']['y'][out_bounds_predictions],\n",
    "    color=\"black\",\n",
    "    marker=\"+\",\n",
    "    alpha=0.5,\n",
    "    label=\"Outside interval\",\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    dataframes_dict_X_y['df_all_concat_lin_corr']['predictions_all_data'][~out_bounds_predictions],\n",
    "    dataframes_dict_X_y['df_all_concat_lin_corr']['y'][~out_bounds_predictions],\n",
    "    color=\"black\",\n",
    "    alpha=0.5,\n",
    "    label=\"points\",\n",
    ")\n",
    "plt.legend()\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "_ = plt.title(\"Quantiles of heteroscedastic Normal distributed target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_dict_X_y['df_all_concat_lin_corr'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_dict_X_y['df_all_concat_lin_corr']['model_qr_05_fit'].predict(np.array([[600]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_dict_X_y['df_all_concat_lin_corr']['model_qr_95_fit'].predict(np.array([[600]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_bounds_predictions.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_dict_X_y['df_all_concat_lin_corr']['y'].count() / (dataframes_dict_X_y['df_all_concat_lin_corr']['y'].count() + out_bounds_predictions.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mapie['y_test'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mapie['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mapie['y_pred'] = y_pred\n",
    "df_mapie['y_test'] = dataframes_dict_X_y['df_all_concat_lin_corr']['y_test'].reset_index(drop=True)\n",
    "df_mapie['y_pis_lower'] = y_pis[:,0,:]\n",
    "df_mapie['y_pis_upper'] = y_pis[:,1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPORTING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_model = rf_grid.best_estimator_\n",
    "rf_model.fit(dataframes_dict_X_y['df_all_concat_lin_corr']['X'], dataframes_dict_X_y['df_all_concat_lin_corr']['y'])\n",
    "joblib.dump(rf_model, utils.DIR_MODELS/\"rf_model_regressor.pkl\")\n",
    "joblib.dump(dataframes_dict_X_y['df_all_concat_lin_corr']['model_qr_05_fit'], utils.DIR_MODELS/\"qr_model_05.pkl\")\n",
    "joblib.dump(dataframes_dict_X_y['df_all_concat_lin_corr']['model_qr_95_fit'], utils.DIR_MODELS/\"qr_model_95.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_dict_X_y['df_all_concat_capacity_shortwave_down']['X_train']['capacity_mw'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env_renewable_power_plants_pred': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "60bc2f3e2ae26542789000890b40dee3a700b323ee2b6f35697d2a36a7d239d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
